From 8b42120b8b83c9a12281dadf11d62fbd45ce5fff Mon Sep 17 00:00:00 2001
From: Deepali Chourasia <deepch23@in.ibm.com>
Date: Wed, 17 Apr 2024 12:22:59 +0000
Subject: [PATCH] Revert "Add --host-triple option. Previously the tool was
 using"

This reverts commit 4bc5c7969b209193ffbc73591ead4f8ee6a6d5a3.
---
 .../compiler/mlir/tools/kernel_gen/BUILD      |  4 +-
 .../mlir/tools/kernel_gen/tf_to_kernel.cc     | 39 +++++--------------
 .../kernels/mlir_generated/build_defs.bzl     |  9 -----
 3 files changed, 13 insertions(+), 39 deletions(-)

diff --git a/tensorflow/compiler/mlir/tools/kernel_gen/BUILD b/tensorflow/compiler/mlir/tools/kernel_gen/BUILD
index 71d85d2c96e..30ae20f6b77 100644
--- a/tensorflow/compiler/mlir/tools/kernel_gen/BUILD
+++ b/tensorflow/compiler/mlir/tools/kernel_gen/BUILD
@@ -17,6 +17,7 @@ load(
 )
 load(
     "//tensorflow/core/platform:build_config.bzl",
+    "if_llvm_aarch64_available",
     "if_llvm_system_z_available",
     "tf_proto_library",
 )
@@ -108,7 +109,6 @@ tf_cc_binary(
         "//tensorflow/compiler/mlir/tensorflow",
         "//tensorflow/core:lib",
         "@com_google_absl//absl/strings",
-        "@llvm-project//llvm:AArch64CodeGen",  # fixdeps: keep
         "@llvm-project//llvm:ARMCodeGen",  # fixdeps: keep
         "@llvm-project//llvm:Analysis",
         "@llvm-project//llvm:CodeGen",
@@ -126,6 +126,8 @@ tf_cc_binary(
         "@llvm-project//mlir:ToLLVMIRTranslation",
     ] + if_llvm_system_z_available([
         "@llvm-project//llvm:SystemZCodeGen",  # fixdeps: keep
+    ]) + if_llvm_aarch64_available([
+        "@llvm-project//llvm:AArch64CodeGen",  # fixdeps: keep
     ]),
 )
 
diff --git a/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel.cc b/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel.cc
index e6ab814216a..8d5d583a2dc 100644
--- a/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel.cc
+++ b/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel.cc
@@ -17,7 +17,6 @@
 // This file implements the entry point to compile a tf op to a kernel.
 //
 //===----------------------------------------------------------------------===//
-#include <memory>
 #include <string>
 #include <utility>
 #include <vector>
@@ -51,15 +50,10 @@ namespace {
 
 static llvm::codegen::RegisterCodeGenFlags CGF;
 
-std::unique_ptr<llvm::TargetMachine> GetTargetMachine(
-    llvm::StringRef host_triple, llvm::Module* module) {
+std::unique_ptr<llvm::TargetMachine> GetTargetMachine(llvm::Module* module) {
   llvm::Triple triple(module->getTargetTriple());
   if (triple.getTriple().empty()) {
-    if (!host_triple.empty()) {
-      triple = llvm::Triple(host_triple);
-    } else {
-      triple = llvm::Triple(llvm::sys::getDefaultTargetTriple());
-    }
+    triple = llvm::Triple(llvm::sys::getDefaultTargetTriple());
     module->setTargetTriple(triple.getTriple());
   }
 
@@ -77,15 +71,14 @@ std::unique_ptr<llvm::TargetMachine> GetTargetMachine(
 }
 
 // Compiles the given MLIR module via LLVM into an executable binary format.
-StatusOr<std::string> EmitToBinary(llvm::StringRef host_triple,
-                                   mlir::ModuleOp module) {
+StatusOr<std::string> EmitToBinary(mlir::ModuleOp module) {
   // Translate the module.
   llvm::LLVMContext llvm_context;
   mlir::registerLLVMDialectTranslation(*module->getContext());
   std::unique_ptr<llvm::Module> llvm_module =
       mlir::translateModuleToLLVMIR(module, llvm_context);
 
-  auto target_machine = GetTargetMachine(host_triple, llvm_module.get());
+  auto target_machine = GetTargetMachine(llvm_module.get());
   llvm_module->setDataLayout(target_machine->createDataLayout());
 
   // Run LLVM's mid-level optimizer to clean up the IR.
@@ -113,7 +106,6 @@ StatusOr<std::string> EmitToBinary(llvm::StringRef host_triple,
 }
 
 Status Run(llvm::StringRef input_file, llvm::StringRef output_file,
-           llvm::StringRef host_triple,
            llvm::ArrayRef<std::string> architectures,
            llvm::ArrayRef<int64_t> tile_sizes,
            llvm::ArrayRef<int64_t> unroll_factors, int64_t max_supported_rank,
@@ -138,7 +130,7 @@ Status Run(llvm::StringRef input_file, llvm::StringRef output_file,
                               /*apply_cl_options=*/true));
 
   // Get binary.
-  TF_ASSIGN_OR_RETURN(std::string binary, EmitToBinary(host_triple, *module));
+  TF_ASSIGN_OR_RETURN(std::string binary, EmitToBinary(*module));
 
   // Write .a file.
   TF_RETURN_IF_ERROR(
@@ -175,8 +167,6 @@ int main(int argc, char** argv) {
   llvm::cl::opt<bool> jit_compile(
       "jit", llvm::cl::desc("Generate only a JIT compiler invocation."),
       llvm::cl::init(false));
-  llvm::cl::opt<std::string> host_triple(
-      "host-triple", llvm::cl::desc("Override host triple for module"));
   llvm::cl::list<std::string> architectures(
       "arch", llvm::cl::desc("target architectures (e.g. sm_70 or compute_75)"),
       llvm::cl::ZeroOrMore, llvm::cl::CommaSeparated);
@@ -199,25 +189,16 @@ int main(int argc, char** argv) {
       llvm::cl::init(false));
 
   tensorflow::InitMlir y(&argc, &argv);
-
-  LLVMInitializeX86Target();
-  LLVMInitializeX86TargetInfo();
-  LLVMInitializeX86TargetMC();
-  LLVMInitializeX86AsmPrinter();
-
-  LLVMInitializeAArch64Target();
-  LLVMInitializeAArch64TargetInfo();
-  LLVMInitializeAArch64TargetMC();
-  LLVMInitializeAArch64AsmPrinter();
-
+  llvm::InitializeNativeTarget();
+  llvm::InitializeNativeTargetAsmPrinter();
   mlir::registerPassManagerCLOptions();
   mlir::registerMLIRContextCLOptions();
   llvm::cl::ParseCommandLineOptions(argc, argv, "TF op kernel generator\n");
 
   auto status = tensorflow::kernel_gen::Run(
-      input_file, output_file, host_triple, architectures, tile_sizes,
-      unroll_factors, max_supported_rank, print_ptx, print_llvmir, enable_ftz,
-      index_64bit, jit_compile, jit_i64_indexed_for_large_tensors);
+      input_file, output_file, architectures, tile_sizes, unroll_factors,
+      max_supported_rank, print_ptx, print_llvmir, enable_ftz, index_64bit,
+      jit_compile, jit_i64_indexed_for_large_tensors);
   if (!status.ok()) {
     LOG(ERROR) << status;
     return 1;
diff --git a/tensorflow/core/kernels/mlir_generated/build_defs.bzl b/tensorflow/core/kernels/mlir_generated/build_defs.bzl
index 2029ad9fb2c..dbe565687c6 100644
--- a/tensorflow/core/kernels/mlir_generated/build_defs.bzl
+++ b/tensorflow/core/kernels/mlir_generated/build_defs.bzl
@@ -148,7 +148,6 @@ def _gen_kernel_bin_impl(ctx):
         arguments = cmd_args + [
             "--tile_sizes=%s" % ctx.attr.tile_size,
             "--max-supported-rank=%s" % ctx.attr.max_supported_rank,
-            "--host-triple=%s" % ctx.attr.host_triple,
             "--arch=%s" % ",".join(ctx.attr.gpu_archs),
             "--input=%s" % ctx.file.mlir_op.path,
             "--output=%s" % gpu_bin.path,
@@ -184,7 +183,6 @@ _gen_kernel_bin_rule = rule(
         "tile_size": attr.string(mandatory = True),
         "unroll_factors": attr.string(),
         "max_supported_rank": attr.int(),
-        "host_triple": attr.string(mandatory = True),
         "gpu_archs": attr.string_list(),
         "jit": attr.bool(),
         "jit_i64_indexed_for_large_tensors": attr.bool(),
@@ -337,12 +335,6 @@ def _gen_kernel_library(
                 platform = platform,
                 type = type,
             )
-
-            host_triple = select({
-                "@platforms//cpu:aarch64": "aarch64-unknown-linux-gnu",  # copybara:comment_replace "//third_party/bazel_platforms/cpu:aarch64": "aarch64-unknown-linux-gnu",
-                "//conditions:default": "x86_64-unknown-linux-gnu",
-            })
-
             _gen_kernel_bin_rule(
                 name = "{op}_{name}_{platform}_{type}_{output_type}_kernel_generator".format(
                     op = op,
@@ -353,7 +345,6 @@ def _gen_kernel_library(
                 ),
                 data_type = type,
                 extra_args = extra_args,
-                host_triple = host_triple,
                 gpu_archs = gpu_archs,
                 jit = jit,
                 max_supported_rank = max_supported_rank,
-- 
2.40.1

