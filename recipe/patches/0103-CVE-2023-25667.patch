From 06ade1d0372f2252803c622ff8229de982191798 Mon Sep 17 00:00:00 2001
From: Andrei Pikas <github@mail.api.win>
Date: Sat, 15 Oct 2022 22:26:47 +0300
Subject: [PATCH] Fix integer overflow for multiframe gifs.

---
 .../core/kernels/image/decode_image_op.cc       |   4 ++--
 tensorflow/core/lib/gif/gif_io.cc               |  14 +++++++-------
 tensorflow/core/lib/gif/gif_io_test.cc          |   5 +++--
 .../core/lib/gif/testdata/3g_multiframe.gif     | Bin 0 -> 22703 bytes
 tensorflow/core/lib/gif/testdata/BUILD          |   1 +
 5 files changed, 13 insertions(+), 11 deletions(-)
 create mode 100644 tensorflow/core/lib/gif/testdata/3g_multiframe.gif

diff --git a/tensorflow/core/kernels/image/decode_image_op.cc b/tensorflow/core/kernels/image/decode_image_op.cc
index 16be92acd2a..766af7fae79 100644
--- a/tensorflow/core/kernels/image/decode_image_op.cc
+++ b/tensorflow/core/kernels/image/decode_image_op.cc
@@ -452,12 +452,12 @@ class DecodeImageV2Op : public OpKernel {
     // allocation til after dtype conversion is done. `gif`::Decode` supports
     // uint8 only.
     Tensor* output = nullptr;
-    int buffer_size = 0;
+    ptrdiff_t buffer_size = 0;
     string error_string;
     uint8* buffer = gif::Decode(
         input.data(), input.size(),
         [&](int num_frames, int width, int height, int channels) -> uint8* {
-          buffer_size = num_frames * height * width * channels;
+          buffer_size = ptrdiff_t(num_frames) * height * width * channels;
 
           Status status;
           // By the existing API, we support decoding GIF with `decode_jpeg` or
diff --git a/tensorflow/core/lib/gif/gif_io.cc b/tensorflow/core/lib/gif/gif_io.cc
index ba4aa1156db..dddb8708c5e 100644
--- a/tensorflow/core/lib/gif/gif_io.cc
+++ b/tensorflow/core/lib/gif/gif_io.cc
@@ -105,7 +105,7 @@ uint8* Decode(const void* srcdata, int datasize,
   uint8* const dstdata =
       allocate_output(target_num_frames, width, height, channel);
   if (!dstdata) return nullptr;
-  for (int k = 0; k < target_num_frames; k++) {
+  for (ptrdiff_t k = 0; k < target_num_frames; k++) {
     uint8* this_dst = dstdata + k * width * channel * height;
 
     SavedImage* this_image = &gif_file->SavedImages[k];
@@ -125,10 +125,10 @@ uint8* Decode(const void* srcdata, int datasize,
 
     if (k > 0) {
       uint8* last_dst = dstdata + (k - 1) * width * channel * height;
-      for (int i = 0; i < height; ++i) {
+      for (ptrdiff_t i = 0; i < height; ++i) {
         uint8* p_dst = this_dst + i * width * channel;
         uint8* l_dst = last_dst + i * width * channel;
-        for (int j = 0; j < width; ++j) {
+        for (ptrdiff_t j = 0; j < width; ++j) {
           p_dst[j * channel + 0] = l_dst[j * channel + 0];
           p_dst[j * channel + 1] = l_dst[j * channel + 1];
           p_dst[j * channel + 2] = l_dst[j * channel + 2];
@@ -141,9 +141,9 @@ uint8* Decode(const void* srcdata, int datasize,
       // If the first frame does not fill the entire canvas then fill the
       // unoccupied canvas with zeros (black).
       if (k == 0) {
-        for (int i = 0; i < height; ++i) {
+        for (ptrdiff_t i = 0; i < height; ++i) {
           uint8* p_dst = this_dst + i * width * channel;
-          for (int j = 0; j < width; ++j) {
+          for (ptrdiff_t j = 0; j < width; ++j) {
             p_dst[j * channel + 0] = 0;
             p_dst[j * channel + 1] = 0;
             p_dst[j * channel + 2] = 0;
@@ -165,9 +165,9 @@ uint8* Decode(const void* srcdata, int datasize,
       return nullptr;
     }
 
-    for (int i = imgTop; i < imgBottom; ++i) {
+    for (ptrdiff_t i = imgTop; i < imgBottom; ++i) {
       uint8* p_dst = this_dst + i * width * channel;
-      for (int j = imgLeft; j < imgRight; ++j) {
+      for (ptrdiff_t j = imgLeft; j < imgRight; ++j) {
         GifByteType color_index =
             this_image->RasterBits[(i - img_desc->Top) * (img_desc->Width) +
                                    (j - img_desc->Left)];
diff --git a/tensorflow/core/lib/gif/gif_io_test.cc b/tensorflow/core/lib/gif/gif_io_test.cc
index 38c18191169..32e63480720 100644
--- a/tensorflow/core/lib/gif/gif_io_test.cc
+++ b/tensorflow/core/lib/gif/gif_io_test.cc
@@ -52,7 +52,7 @@ void TestDecodeGif(Env* env, DecodeGifTestCase testcase) {
         w = width;
         h = height;
         c = channels;
-        return new uint8[frame_cnt * height * width * channels];
+        return new uint8[ptrdiff_t(frame_cnt) * height * width * channels];
       },
       &error_string));
   ASSERT_NE(imgdata, nullptr);
@@ -72,7 +72,8 @@ TEST(GifTest, Gif) {
        {testdata_path + "optimized.gif", 12, 20, 40, 3},
        {testdata_path + "red_black.gif", 1, 16, 16, 3},
        {testdata_path + "scan.gif", 12, 20, 40, 3},
-       {testdata_path + "squares.gif", 2, 16, 16, 3}});
+       {testdata_path + "squares.gif", 2, 16, 16, 3},
+       {testdata_path + "3g_multiframe.gif", 519, 1920, 1080, 3}});
 
   for (const auto& tc : testcases) {
     TestDecodeGif(env, tc);
diff --git a/tensorflow/core/lib/gif/testdata/3g_multiframe.gif b/tensorflow/core/lib/gif/testdata/3g_multiframe.gif
new file mode 100644
index 0000000000000000000000000000000000000000..f9286dc85c0084b3125e4ff7d605a695dbb8a5cd
GIT binary patch
literal 22703
zcmeI1Sxj4J7RO180!j%%Z4@j>Q@SV+LI_Hu;DM@Qx_|*MD2;+e(v(S~KnP7yTLp_$
zmDy|qwxLN1E)YV1U}HA3*%zBF8#Z3ah8-ZptTtxz?(2PmI+bRm>HA3Y-Ix3F={_8t
z`}_UR`I3?ok$?LK(GTfM_VMw0y*}Up75IOx!28~}uwS0~>hr&+eR(W8=FJ_i>+rta
z*Js!3chq)Gwto{Jf3MFD|NSUV<Go`4cOuV<ICmb9gFZ~DNA)y4sz7|4Gb`$87FLFR
zUcNuMw`Jl+#8>RI6TNpOH8J0c>y!IhWp&6Ob+Z$FOvUYl;$82i^s^o}qi#fgE$(l7
z%1mocxs@`&e%_An%XujtXjgV;J}7@TmD};6FZ(I`YYDe=hL^V}zLm=BdMO~7bT1{m
z?pLG4H{UvdhB)&NDDNCTCxv<zg;gJ>HlPQ4mnDpkFV9H_`!tHi&npgK`2DL-SzooE
zlko@El$>uR4HyA;V+Q(hZB8cOZM_;Re(OE#5M)>s-8lS>d}z?5nQTtIjUDD&)>M6$
zU&)6Bwk`F83h#Tkks-TD`?UQV#mKPJreBoY#*L1+ov>-`m11=CHAHqssENM&vekwD
z2U+T(fD>AEaZqB!e97L^+4H4{i>!Il{;S$~au_LMf$~vx_Ci@iD{G-VimP3yh#8Mq
zq#mEjUZf#cSc~*etlGuOgq??$s=nBFY3Wzg!M3IA=o70;H_{RhE#EwK`qJ`m_=|1J
z)n~7+F4ts|4y`aQR9{;8J-fASr8bwlx>A=nen?aQ)6^x+Ey7Bhrr~Gns^&IvXQZ~V
zWM7W<4&@+Q+eAH~(>7NnMy|HpJe{+8mvNE3+FE~Ax5{iJMe0~B)j7I0Rx4Y_?%?Wl
z?VNFM<XT7nRL)u_w8CEN8nWuvy2o}NUgtdAcX_=>bg+HBS9)S?y>Bw{@J9c$)0Z~}
zR2SPfxU*N+Hh5~%;Z10%`ts(WwzYkezs_CT6zInfZw;BJE^iIPEA3k&F6-LXsE=Qi
ze#|#GSAWkxyhDFKAa-5<ASfxy@NjQ>uHg|PtHUt9KY!gI3?oMwMIY7V8Yd!{9Y%2!
zZ`~+~5k{G$$CbGz8B)_>l7C`bHz^YQj+iIE2>#Ce7!}@Weu9qOFh5O8I%0WtD*Zdl
zb9`2(W$JAHhDDi4K4Mi}sQJ$NBAeN1ozCTLSZDHtM{Kh{DZjJ5BxpKqb3fa>8@5+O
zzi3!p5_|=or-XOG3)I+6c(E!e+P-u%{fd2=k=12isn6fEYZ}SX4sA=#6~`)z+2zo6
z@HQQ59AUI`y<d67xdCaqoSQ?oP3P8_-%*$TVet1ZgDAY)Wt7HlxlEHuN8RRU>EF98
zs;q9ebvA#?ZBvtvdf=s+?>%-cv)kiX=WThMdf`#8%dGs~>xMPmUXRPR^|}KC8h!jw
zV{e4$iT>!uH-bfDJLB|)LDWXyaMZnB8TulGv~g#w=w4ufzBnx4j(-yB{@b<sk_hyj
zUFo9x`}q3O80wvXEYyRLX*~%ky%U%(dT_v@Cnp3n1$oJ+haZF(C@6H(+clzx2jdK7
zY1F2@Ow^;u3`03y+O&@+dK6t?sK^XxMhH>k$7&7KY;<#oQZ#;oZ=mH-oA+x_!nkPz
zogi&KU=s;Hbr>p%0WD#E$)e9fj8znL%Ll;|qQp4kuT|8RkHV8DQZkI!8Pb-6u@e*6
z0^^OwfV&Y%$>Ni>#+xkk-N^I_@oB#CHxBh~R93PiW7=2^N$*DIPe{%=j5T8ctuf?e
z>G=>7LxgTURx=^J7-#x@lG=KlnJml6Fx9H0ttWUBvMU9qI&}aODNL6CP;08!qM32Z
z3HepN>6V_#{6v$iD3~@iz*6R?wh6D|7l-M#&u&(NU&>@rh`G@p!}=^(JV}Z(-wC3z
zz6eiwT%KWWLdaN&vEs+{0&{cN?lx3X%9HE0=9UOdTS~h4Nj2YmH-^@R&PsV&J8f=7
z%G$8`;-?J`Gc#c~JB^(3tSQ98LSfh^YsAl5<1B4yH1;WG%5!#xg^ic7PxHjjy9zAr
znY-KZ!j!4rT1!VZraeO`p5pQ?oq4qOvzinof7;STkhPz)iIpP`OE+<MN2Xt@>VAlo
zL&0>M50<FL<E%YZw2lkmsV~GC)?S9J<6^Ajg}lJp*SNbgJ1KSgNv*Y?h3U*mmrPIb
ztpgldXKq&N%(Qpf%7tW|SMnt@a}FzSY<E{4Idyg+#0H5lT|d-FW>?~DgOjwbpO~pH
zbs09kO4fCiCwaM9U=yf!cN2uEbH-ZRkQUQjpp?v6`L<y_t@~$9>MO^zZ3LEe|6-H8
z@;GdxK7kyfA6orJC_Ltm<rD==)jQ+idqH$gNjQ3b*BSUeLe3$@O6LQw!4JX$dnifh
zg}3YAhY{GG@^tCKJ^}nFhTcQXLNA8Qz~e}H4?SPHc)$q@69Rjy$mpdHLhT|Hw)c9C
zbm?HceIkwCdy|P?jyz)*<K?~8Jn3@uHM=A;u#X``uN<qhOS7?kwMyyA34z@!%cJ+z
zYtWjw8M~Yy?`yD0HJ>`|3SwY?qaQ~5S*T-@g6(e#mT42?9gnN%{Vm~`)s!=iCk%Oi
zYpiS)d(H8*F>rvDgwdU>b39{V2iWN{-D!d2Ifp*bk%d{ym~l)&@`0{=+1fd$Lpc`6
z<&ZJ!=R=(;5tiFqBU`^1?|d;y=k_x(8#!m3(<(Wa%ad(fx#pZv2l5~xX7h(S=d2dX
z<11yGR|U?OdOB}NgV`#Wan8YV-iS@M^^4Q_%4ZKW=7-f6g}T)KIOu+`Tu+L3%?DLN
z55uvB@-walgaR6ml^f{ST#I3Q21Q9&<Mle%QiK;bC{C9fs|Bv*n94zE7S>cd<61!~
z2Icv3Q-jl`N!Y`mBxB7@p>8b-$A3~IH@C*SSJNu_&zM*X`;1$MSMaBJa!c1W_gdy2
zfl7$A_SU)AvvGoHrQFIDxHs}D1+yBgjX&ewBq#)PHo0xY>E0sl8B+V<;QOH-Jq0(k
z5Uha5<2{C|%AuujoLzjzV`M0XR$>))`8AKJanG<e3FmlH=P|Qz!@6{ZV@lw$a4Lt_
zvvAJo8IKiG3~%NuoO4c(ZEVkoo{V!XgnD5SZp2ulaIM69?UR)wW+u+9JL7ez6eCui
z!o7LT>s0R<^}<4&$5`ieX>p?trNUzsc-{KSQI`hib<B7@uwv9>Q+Pej*Azw&-#`+5
z@x+}3qCbPU3nB)nh=DLM2vPVpvT!fHa37%%!6*!Y3iqoD55R?Ch@uaWMIYgd4ibtY
z7)6m#QIx7E8ZL@K6dywtAIBG;AQU4R#c@#aC#vF4;o<~D$!ExtFYqOagc1~^Bn2u#
zt4gqNNgAT`B(n4rzVtMq6wfHlfJ)D*O3%TinF!K(B<TX4bdf;HW{`3qQm%@01t#So
z$Uh*-KjFz&31k9;TmX@OR*`>!$wUOD2uUfyQ%D2~g+VEYC{z`NUI$aE5M|eqWjFC<
z)r2wzqpTJxt5=mZz-5hy@+M??3%<OSP|jkMv!U`1Re2X&&Ouc4A}jjw6<k6E#Hipy
z6+^0u5x8OuLA{TpKEzYU2~-h-Du$?16;%#XClRzKNZK<zZHhosF=*2eZB|8_gK266
zeE~^d!qZm>bS;CfgXrrj`X)@*BPxx^%3eg!f9BO4K0AC0w}b1SkH4?a4qxB@a_HYD
zzrQ^6=U2Ahe|ZRe2~^yt5Oe|P0?-A3zS{x<EC4J3T>w}BSOD_)>mC3`*e(H>r9dtK
zT>w}BSOARhhZKPkfDwQZfDwQZfDwQZeEui_*d2mN5$q1ZzF=F5fCYdBpbG#C01Lo9
z0!WAd3dmq<1abk`8i91UEk(crzyi<(fCYdBV1xWeKn6wtMgT?tMgT?tMgT?tcZ#p`
z0N5S=Q37zA1oj2sHVJHvwxbbX0bl{>0>A>m0+0?tIs`MqpJNip1t1rITmW(b$OZo+
Hxgh?Z>XK=-

literal 0
HcmV?d00001

diff --git a/tensorflow/core/lib/gif/testdata/BUILD b/tensorflow/core/lib/gif/testdata/BUILD
index 1d020d116e4..431f4e346e2 100644
--- a/tensorflow/core/lib/gif/testdata/BUILD
+++ b/tensorflow/core/lib/gif/testdata/BUILD
@@ -15,6 +15,7 @@ filegroup(
         "scan.gif",
         "red_black.gif",
         "squares.gif",
+        "3g_multiframe.gif",
         "pendulum_sm.gif",
         # Add groundtruth frames for `pendulum_sm.gif`.
         # PNG format because it's lossless.
-- 
2.34.1

